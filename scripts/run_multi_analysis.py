"""
í†µí•© ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ìœ í˜•êµ¬ë¶„ë³„ ì„±ê³¼ ë¶„ì„ê³¼ ì¼ë³„ ì§‘ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
ì°¨ì›ë³„ ì„¸ë¶€ ë¶„ì„ì€ multi_analysis_dimension_detail.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

ì‚¬ìš©ë²•:
- ë ˆê±°ì‹œ: python run_multi_analysis.py
- ë©€í‹°í´ë¼ì´ì–¸íŠ¸: python run_multi_analysis.py --client clientA

ê²°ê³¼ëŠ” data/type/ (ë˜ëŠ” data/{client}/type/) ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤.
"""

import argparse
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Optional
import sys
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.common.paths import ClientPaths, parse_client_arg, PROJECT_ROOT

# ë ˆê±°ì‹œ ê²½ë¡œ ì„¤ì • (ê¸°ë³¸ê°’)
BASE_DIR = Path(__file__).parent.parent
DATA_TYPE_DIR = BASE_DIR / 'data' / 'type'


def run_multi_analysis(paths: Optional[ClientPaths] = None):
    """
    í†µí•© ë¶„ì„ ì‹¤í–‰

    Args:
        paths: ClientPaths ê°ì²´ (ë©€í‹°í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ) ë˜ëŠ” None (ë ˆê±°ì‹œ ëª¨ë“œ)
    """
    # ê²½ë¡œ ì„¤ì • (í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ vs ë ˆê±°ì‹œ ëª¨ë“œ)
    if paths:
        data_type_dir = paths.type
        input_file = data_type_dir / 'merged_data.csv'
        output_dir = data_type_dir
    else:
        data_type_dir = DATA_TYPE_DIR
        input_file = DATA_TYPE_DIR / 'merged_data.csv'
        output_dir = DATA_TYPE_DIR

    print("=" * 100)
    print("í†µí•© ë§ˆì¼€íŒ… ë°ì´í„° ë¶„ì„ ì‹œì‘")
    if paths:
        print(f"í´ë¼ì´ì–¸íŠ¸: {paths.client_id}")
    print("=" * 100)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ì…ë ¥ íŒŒì¼: {input_file}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")

    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not input_file.exists():
        print(f"\nâŒ ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_file}")
        return None

    # ë°ì´í„° ë¡œë“œ
    print("\në°ì´í„° ë¡œë”© ì¤‘...")
    df = pd.read_csv(input_file, thousands=',', low_memory=False)
    df['ì¼'] = pd.to_datetime(df['ì¼'])

    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ë³€í™˜
    numeric_cols = ['ë¹„ìš©', 'ë…¸ì¶œ', 'í´ë¦­', 'ì „í™˜ìˆ˜', 'ì „í™˜ê°’']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    print(f"ì´ ë°ì´í„°: {len(df):,}í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")

    # ============================================================================
    # 1. ìœ í˜•êµ¬ë¶„ë³„ ì„±ê³¼ ë¶„ì„
    # ============================================================================
    print("\n" + "=" * 100)
    print("1ë‹¨ê³„: ìœ í˜•êµ¬ë¶„ë³„ ì„±ê³¼ ë¶„ì„")
    print("=" * 100)

    category_summary = df.groupby('ìœ í˜•êµ¬ë¶„').agg({
        'ë¹„ìš©': 'sum',
        'ë…¸ì¶œ': 'sum',
        'í´ë¦­': 'sum',
        'ì „í™˜ìˆ˜': 'sum',
        'ì „í™˜ê°’': 'sum'
    }).reset_index()

    category_summary['ROAS'] = (category_summary['ì „í™˜ê°’'] / category_summary['ë¹„ìš©'] * 100).replace([np.inf, -np.inf], 0).fillna(0)
    category_summary['CPA'] = (category_summary['ë¹„ìš©'] / category_summary['ì „í™˜ìˆ˜']).replace([np.inf, -np.inf], 0).fillna(0)
    category_summary['CPC'] = (category_summary['ë¹„ìš©'] / category_summary['í´ë¦­']).replace([np.inf, -np.inf], 0).fillna(0)
    category_summary['CTR'] = (category_summary['í´ë¦­'] / category_summary['ë…¸ì¶œ'] * 100).fillna(0)
    category_summary['CVR'] = (category_summary['ì „í™˜ìˆ˜'] / category_summary['í´ë¦­'] * 100).fillna(0)

    print("\nìœ í˜•êµ¬ë¶„ë³„ ì„±ê³¼:")
    for _, row in category_summary.iterrows():
        print(f"  {row['ìœ í˜•êµ¬ë¶„']}: ROAS {row['ROAS']:.1f}%, CPA {row['CPA']:,.0f}ì›")

    output_dir.mkdir(parents=True, exist_ok=True)
    output_file_1 = output_dir / 'analysis_category_summary.csv'
    category_summary.to_csv(output_file_1, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ ì €ì¥ ì™„ë£Œ: {output_file_1}")

    # ============================================================================
    # 2. ì¼ë³„ ì§‘ê³„ ë°ì´í„°
    # ============================================================================
    print("\n" + "=" * 100)
    print("2ë‹¨ê³„: ì¼ë³„ ì§‘ê³„ ë°ì´í„° ìƒì„±")
    print("=" * 100)

    daily_data = df.groupby('ì¼').agg({
        'ë¹„ìš©': 'sum',
        'ë…¸ì¶œ': 'sum',
        'í´ë¦­': 'sum',
        'ì „í™˜ìˆ˜': 'sum',
        'ì „í™˜ê°’': 'sum'
    }).reset_index()

    daily_data['ROAS'] = (daily_data['ì „í™˜ê°’'] / daily_data['ë¹„ìš©'] * 100).replace([np.inf, -np.inf], 0).fillna(0)
    daily_data['CPA'] = (daily_data['ë¹„ìš©'] / daily_data['ì „í™˜ìˆ˜']).replace([np.inf, -np.inf], 0).fillna(0)
    daily_data['CTR'] = (daily_data['í´ë¦­'] / daily_data['ë…¸ì¶œ'] * 100).fillna(0)
    daily_data['CVR'] = (daily_data['ì „í™˜ìˆ˜'] / daily_data['í´ë¦­'] * 100).fillna(0)

    print(f"ì¼ë³„ ë°ì´í„°: {len(daily_data)}ì¼")
    print(f"ê¸°ê°„: {daily_data['ì¼'].min().date()} ~ {daily_data['ì¼'].max().date()}")

    output_file_2 = output_dir / 'analysis_daily_summary.csv'
    daily_data.to_csv(output_file_2, index=False, encoding='utf-8-sig')
    print(f"âœ“ ì €ì¥ ì™„ë£Œ: {output_file_2}")

    # ============================================================================
    # ìµœì¢… ìš”ì•½
    # ============================================================================
    print("\n" + "=" * 100)
    print("ë¶„ì„ ì™„ë£Œ!")
    if paths:
        print(f"í´ë¼ì´ì–¸íŠ¸: {paths.client_id}")
    print("=" * 100)

    print(f"\nì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nìƒì„±ëœ íŒŒì¼:")
    print(f"  1. {output_file_1} - ìœ í˜•êµ¬ë¶„ë³„ ì„±ê³¼")
    print(f"  2. {output_file_2} - ì¼ë³„ ì§‘ê³„")

    print("\nì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
    print(f"  - ì´ {len(df):,}ê°œ ë°ì´í„° ë¶„ì„")
    print(f"  - {len(category_summary)}ê°œ ìœ í˜•êµ¬ë¶„ ë¶„ì„")
    print(f"  - {len(daily_data)}ì¼ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±")
    print(f"\nğŸ’¡ ì°¨ì›ë³„ ì„¸ë¶€ ë¶„ì„ì€ multi_analysis_dimension_detail.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")

    print("\n" + "=" * 100)

    return {
        'category_summary': category_summary,
        'daily_data': daily_data
    }


def main(client_id: Optional[str] = None):
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í†µí•© ë¶„ì„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--client', type=str, default=None,
                        help='í´ë¼ì´ì–¸íŠ¸ ID (ë©€í‹°í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ)')
    args = parser.parse_args()

    actual_client_id = args.client or client_id

    # í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ ì„¤ì •
    paths = None
    if actual_client_id:
        paths = ClientPaths(actual_client_id).ensure_dirs()
        print(f"[ë©€í‹°í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ] í´ë¼ì´ì–¸íŠ¸: {actual_client_id}")

    try:
        run_multi_analysis(paths)
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
