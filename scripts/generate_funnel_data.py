"""
GA4 ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AARRR í¼ë„ ë¶„ì„ ë°ì´í„° ìƒì„±

í†µí•© ë²„ì „: í†µê³„ ë¶„ì„ + ë§ˆì¼€í„° ì¹œí™”ì  ì¸ì‚¬ì´íŠ¸
- K-Means í´ëŸ¬ìŠ¤í„°ë§ + BCG Matrix ë¶„ì„
- ì¹´ì´ì œê³± A/B í…ŒìŠ¤íŠ¸ + ë§¤ì¶œ ì„íŒ©íŠ¸ í™˜ì‚°
- 7ì¼/30ì¼ ì´íƒˆ ì˜ˆì¸¡ + CRM ë ˆì‹œí”¼
- ì¹´í…Œê³ ë¦¬ë³„ ì„ê³„ê°’ ì„¤ì •
"""
import pandas as pd
import json
import os
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')


# ============================================================================
# 1. ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ (Configuration)
# ============================================================================

# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / 'data'
GA4_DIR = DATA_DIR / 'GA4'
FUNNEL_DIR = DATA_DIR / 'funnel'

# í¼ë„ ìˆœì„œ ë° ì¹œì ˆí•œ ì´ë¦„ ë§¤í•‘
FUNNEL_ORDER = ['ìœ ì…', 'í™œë™', 'ê´€ì‹¬', 'ê²°ì œì§„í–‰', 'êµ¬ë§¤ì™„ë£Œ']
FUNNEL_MAPPING = {
    'ìœ ì…': 'Acquisition',
    'í™œë™': 'Activation',
    'ê´€ì‹¬': 'Consideration',
    'ê²°ì œì§„í–‰': 'Conversion',
    'êµ¬ë§¤ì™„ë£Œ': 'Purchase'
}
FRIENDLY_NAMES = {
    'ìœ ì…': 'ë§¤ì¥ ë°©ë¬¸ (ìœ ì…)',
    'í™œë™': 'ìƒí’ˆ êµ¬ê²½ (í™œë™)',
    'ê´€ì‹¬': 'ì¥ë°”êµ¬ë‹ˆ (ê´€ì‹¬)',
    'ê²°ì œì§„í–‰': 'ê²°ì œì°½ ì§„ì…',
    'êµ¬ë§¤ì™„ë£Œ': 'êµ¬ë§¤ ì„±ê³µ'
}

# ============================================================================
# ì¹´í…Œê³ ë¦¬ë³„ ì„ê³„ê°’ ì„¤ì • (Thresholds by Category)
# ============================================================================
CATEGORY_THRESHOLDS = {
    'default': {
        'activation_rate_warning': 50.0,      # ìœ ì…â†’í™œë™ ì „í™˜ ê²½ê³  ê¸°ì¤€ (%)
        'cart_conversion_warning': 20.0,      # ê´€ì‹¬â†’êµ¬ë§¤ ì „í™˜ ê²½ê³  ê¸°ì¤€ (%)
        'checkout_conversion_warning': 50.0,  # ê²°ì œì§„í–‰â†’êµ¬ë§¤ ì „í™˜ ê²½ê³  ê¸°ì¤€ (%)
        'ab_significance': 0.05,              # A/B í…ŒìŠ¤íŠ¸ ìœ ì˜ìˆ˜ì¤€ (p-value)
        'churn_alert_threshold': -20.0,       # ì´íƒˆ ê²½ê³  ê¸°ì¤€ (%)
        'improvement_threshold': 20.0,        # ì„±ê³¼ ê°œì„  ê¸°ì¤€ (%)
        'high_risk_threshold': -30.0,         # ê³ ìœ„í—˜ ê¸°ì¤€ (%)
        'high_improvement_threshold': 30.0,   # ê³ ì„±ì¥ ê¸°ì¤€ (%)
        'min_sample_size': 5,                 # ì¹´ì´ì œê³± ìµœì†Œ ìƒ˜í”Œ
        'min_users_for_analysis': 100,        # ë¶„ì„ ìµœì†Œ ìœ ì € ìˆ˜
        'potential_uplift_min': 100000        # ìµœì†Œ ë§¤ì¶œ ì„íŒ©íŠ¸ (ì›)
    },
    'fashion': {  # íŒ¨ì…˜: ì¶©ë™êµ¬ë§¤ å¤š, ì „í™˜ìœ¨ ë‚®ìŒ
        'activation_rate_warning': 40.0,
        'cart_conversion_warning': 15.0,
        'checkout_conversion_warning': 45.0,
        'ab_significance': 0.05,
        'churn_alert_threshold': -25.0,
        'improvement_threshold': 25.0,
        'high_risk_threshold': -35.0,
        'high_improvement_threshold': 35.0,
        'min_sample_size': 5,
        'min_users_for_analysis': 100,
        'potential_uplift_min': 100000
    },
    'food': {  # ì‹í’ˆ: ì¬êµ¬ë§¤ å¤š, ì „í™˜ìœ¨ ë†’ìŒ
        'activation_rate_warning': 60.0,
        'cart_conversion_warning': 30.0,
        'checkout_conversion_warning': 60.0,
        'ab_significance': 0.05,
        'churn_alert_threshold': -15.0,
        'improvement_threshold': 15.0,
        'high_risk_threshold': -25.0,
        'high_improvement_threshold': 25.0,
        'min_sample_size': 5,
        'min_users_for_analysis': 50,
        'potential_uplift_min': 50000
    },
    'electronics': {  # ê°€ì „: ê³ ê´€ì—¬, ì „í™˜ìœ¨ ë‚®ì§€ë§Œ ê°ë‹¨ê°€ ë†’ìŒ
        'activation_rate_warning': 45.0,
        'cart_conversion_warning': 10.0,
        'checkout_conversion_warning': 40.0,
        'ab_significance': 0.05,
        'churn_alert_threshold': -20.0,
        'improvement_threshold': 20.0,
        'high_risk_threshold': -30.0,
        'high_improvement_threshold': 30.0,
        'min_sample_size': 3,
        'min_users_for_analysis': 30,
        'potential_uplift_min': 500000
    }
}

# í˜„ì¬ ì‚¬ìš©í•  ì¹´í…Œê³ ë¦¬ (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
CURRENT_CATEGORY = os.environ.get('BUSINESS_CATEGORY', 'default')

# CRM ì•¡ì…˜ ê°€ì´ë“œ (ì´íƒˆ ë°œìƒ ì‹œ ì œì•ˆí•  ë ˆì‹œí”¼)
CRM_RECIPES = {
    'í™œë™': {
        'diagnosis': "ê³ ê°ë“¤ì´ ìƒí’ˆì„ ì˜ ì•ˆ ëˆŒëŸ¬ë´…ë‹ˆë‹¤.",
        'action': "ğŸ‘€ 'ìš”ì¦˜ ì´ê²Œ ì œì¼ ì˜ ë‚˜ê°€ìš”ğŸ”¥' ë² ìŠ¤íŠ¸ ìƒí’ˆ íë ˆì´ì…˜ ë°°ë„ˆë¥¼ ë©”ì¸ì— ë„ì›Œë³´ì„¸ìš”.",
        'technical': "ëœë”©í˜ì´ì§€ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    },
    'ê´€ì‹¬': {
        'diagnosis': "ì¥ë°”êµ¬ë‹ˆì— ë‹´ê³  ìŠì–´ë²„ë¦° ë¶„ë“¤ì´ ë§ì•„ìš”.",
        'action': "ğŸ›’ ì´íƒˆ 1ì‹œê°„ í›„ 'ê³ ê°ë‹˜, ë‹´ì•„ë‘ì‹  ìƒí’ˆì´ ê³§ í’ˆì ˆë¼ìš”' ì•Œë¦¼í†¡ì„ ë°œì†¡í•˜ì„¸ìš”.",
        'technical': "ì¥ë°”êµ¬ë‹ˆ ë¦¬ë§ˆì¸ë” ìº í˜ì¸ì„ ì„¤ì •í•˜ì„¸ìš”."
    },
    'ê²°ì œì§„í–‰': {
        'diagnosis': "ë‹¤ ì‚¬ë ¤ë‹¤ê°€ ê²°ì œ ì§ì „ì— ë‚˜ê°”ì–´ìš”.",
        'action': "ğŸ’³ ê²°ì œ ì˜¤ë¥˜ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ê³ , 'ì§€ê¸ˆ ê²°ì œí•˜ë©´ ë‚´ì¼ ë„ì°© ğŸšš' ë¬¸êµ¬ë¡œ ì•ˆì‹¬ì‹œì¼œì£¼ì„¸ìš”.",
        'technical': "ê²°ì œ í”„ë¡œì„¸ìŠ¤ UX ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤."
    },
    'ìœ ì…': {
        'diagnosis': "ë°©ë¬¸ì ìì²´ê°€ ì¤„ê³  ìˆì–´ìš”.",
        'action': "ğŸ“¢ ê´‘ê³  ë…¸ì¶œì´ ì¤„ì—ˆê±°ë‚˜, ì‹œì¦Œ ì´ìŠˆì¼ ìˆ˜ ìˆì–´ìš”. ìº í˜ì¸ ì˜ˆì‚°ê³¼ í‚¤ì›Œë“œë¥¼ ì ê²€í•˜ì„¸ìš”.",
        'technical': "ë§ˆì¼€íŒ… ìº í˜ì¸ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤."
    }
}

# BCG Matrix ì •ì˜
BCG_MATRIX = {
    'cash_cow': {
        'type': 'Cash Cow (íš¨ì ì±„ë„)',
        'icon': 'ğŸ‘‘',
        'message': 'ë°©ë¬¸ìë„ ë§ê³  êµ¬ë§¤ë„ ì˜í•´ìš”! ìš°ë¦¬ ì‡¼í•‘ëª°ì˜ ê¸°ë‘¥ì…ë‹ˆë‹¤.',
        'action': 'ğŸ‘‰ ì§€ê¸ˆ ê³ ê°ë“¤ì—ê²Œ \'ì„¸íŠ¸ ìƒí’ˆ\'ì„ ì¶”ì²œí•´ì„œ ê°ë‹¨ê°€ë¥¼ ë” ë†’ì—¬ë³´ì„¸ìš”.'
    },
    'hidden_gem': {
        'type': 'Hidden Gem (ìˆ¨ì€ ë³´ì„)',
        'icon': 'ğŸ’',
        'message': 'ì•„ì§ ì†Œë¬¸ì´ ëœ ë‚¬ì§€ë§Œ, ë“¤ì–´ì˜¤ë©´ ë¬´ì¡°ê±´ ì‚¬ë„¤ìš”!',
        'action': 'ğŸ‘‰ í™•ì‹ ì„ ê°€ì§€ì„¸ìš”! ì´ ì±„ë„ ì˜ˆì‚°ì„ 20%ë§Œ ëŠ˜ë ¤ë„ ë§¤ì¶œì´ íŠˆ ê²ë‹ˆë‹¤.'
    },
    'money_pit': {
        'type': 'Money Pit (ë°‘ ë¹ ì§„ ë…)',
        'icon': 'ğŸ’¸',
        'message': 'ì‚¬ëŒë§Œ ë¶ì ì´ê³  ì‹¤ì†ì´ ì—†ì–´ìš”. í—›ëˆ ì“°ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'action': 'ğŸ‘‰ íƒ€ê²Ÿì´ ë„ˆë¬´ ë„“ì–´ìš”. \'ì œì™¸ í‚¤ì›Œë“œ\'ë¥¼ ì„¤ì •í•´ì„œ í—ˆìˆ˜ë¥¼ ê±¸ëŸ¬ë‚´ì„¸ìš”.'
    },
    'dog': {
        'type': 'Dog (ì•„í”ˆ ì†ê°€ë½)',
        'icon': 'ğŸ¤”',
        'message': 'ë°©ë¬¸ë„ ì ê³  ë°˜ì‘ë„ ì—†ì–´ìš”.',
        'action': 'ğŸ‘‰ ì ì‹œ ìš´ì˜ì„ ë©ˆì¶”ê±°ë‚˜, ì´ë¯¸ì§€ì™€ ë¬¸êµ¬ë¥¼ ì™„ì „íˆ ìƒˆë¡­ê²Œ ë°”ê¿”ë³´ì„¸ìš”.'
    }
}

# ë°ì´í„° ë¶€ì¡± ì‹œ ë©”ì‹œì§€
INSUFFICIENT_DATA_MESSAGES = {
    'default': "ì•„ì§ ë°ì´í„°ê°€ ëª¨ìë¼ìš”! ì¡°ê¸ˆë§Œ ë” ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ğŸ¥š",
    'no_file': "ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”! íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš” ğŸ“‚",
    'empty_data': "ë°ì´í„°ê°€ í…… ë¹„ì–´ìˆì–´ìš”! GA4 ì—°ë™ì„ í™•ì¸í•´ì£¼ì„¸ìš” ğŸ”Œ",
    'few_channels': "ì±„ë„ì´ 3ê°œ ë¯¸ë§Œì´ë¼ í´ëŸ¬ìŠ¤í„°ë§ì´ ì–´ë ¤ì›Œìš”. ì±„ë„ì„ ë” ì¶”ê°€í•´ì£¼ì„¸ìš” ğŸ“Š",
    'few_days': "ë¶„ì„í•˜ë ¤ë©´ ìµœì†Œ 14ì¼ì¹˜ ë°ì´í„°ê°€ í•„ìš”í•´ìš”. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš” ğŸ“…",
    'few_users': "ë°©ë¬¸ìê°€ ë„ˆë¬´ ì ì–´ì„œ í†µê³„ì  ì˜ë¯¸ê°€ ì—†ì–´ìš”. íŠ¸ë˜í”½ì„ ë¨¼ì € ëŠ˜ë ¤ë³´ì„¸ìš” ğŸ‘¥",
    'no_conversion': "ì•„ì§ êµ¬ë§¤ ì „í™˜ì´ ì—†ì–´ìš”! ì²« êµ¬ë§¤ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘... ğŸ¯"
}


# ============================================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (Helper Functions)
# ============================================================================

def get_thresholds(category=None):
    """ì¹´í…Œê³ ë¦¬ë³„ ì„ê³„ê°’ ë°˜í™˜"""
    if category is None:
        category = CURRENT_CATEGORY
    return CATEGORY_THRESHOLDS.get(category, CATEGORY_THRESHOLDS['default'])


def format_korean_currency(value):
    """ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í•œêµ­ í™”í ë‹¨ìœ„ë¡œ ë³€í™˜ (ì˜ˆ: 15000000 -> 1,500ë§Œ ì›)"""
    if value is None or pd.isna(value):
        return "0ì›"
    value = float(value)
    if value >= 100000000:  # 1ì–µ ì´ìƒ
        return f"{value/100000000:.1f}ì–µ ì›"
    elif value >= 10000000:  # 1ì²œë§Œ ì´ìƒ
        return f"{value/10000000:.0f}ì²œë§Œ ì›"
    elif value >= 10000:  # 1ë§Œ ì´ìƒ
        return f"{value/10000:,.0f}ë§Œ ì›"
    else:
        return f"{int(value):,}ì›"


def format_number(value):
    """ìˆ«ìì— ì²œ ë‹¨ìœ„ ì½¤ë§ˆ ì¶”ê°€"""
    if value is None or pd.isna(value):
        return "0"
    return f"{int(value):,}"


def safe_division(numerator, denominator, multiply=100):
    """0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€"""
    if denominator is None or denominator == 0:
        return 0
    return float(numerator / denominator * multiply)


def convert_to_serializable(obj):
    """numpy/pandas íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, (np.integer, np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.floating, np.float64, np.float32)):
        return float(obj)
    elif isinstance(obj, (np.bool_, bool)):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(i) for i in obj]
    elif pd.isna(obj):
        return None
    return obj


def check_data_sufficiency(df, thresholds):
    """ë°ì´í„° ì¶©ë¶„ì„± ì²´í¬"""
    issues = []

    if df is None or df.empty:
        return [{'type': 'empty_data', 'message': INSUFFICIENT_DATA_MESSAGES['empty_data']}]

    total_users = df[df['funnel'] == 'ìœ ì…']['Total users'].sum() if 'ìœ ì…' in df['funnel'].values else 0
    if total_users < thresholds['min_users_for_analysis']:
        issues.append({
            'type': 'few_users',
            'message': INSUFFICIENT_DATA_MESSAGES['few_users'],
            'detail': f"í˜„ì¬ {format_number(total_users)}ëª… (ìµœì†Œ {thresholds['min_users_for_analysis']}ëª… í•„ìš”)"
        })

    total_purchase = df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ']['Total users'].sum() if 'êµ¬ë§¤ì™„ë£Œ' in df['funnel'].values else 0
    if total_purchase == 0:
        issues.append({
            'type': 'no_conversion',
            'message': INSUFFICIENT_DATA_MESSAGES['no_conversion']
        })

    unique_days = df['Day'].nunique() if 'Day' in df.columns else 0
    if unique_days < 14:
        issues.append({
            'type': 'few_days',
            'message': INSUFFICIENT_DATA_MESSAGES['few_days'],
            'detail': f"í˜„ì¬ {unique_days}ì¼ (ìµœì†Œ 14ì¼ í•„ìš”)"
        })

    return issues


# ============================================================================
# 3. ìì—°ì–´ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜ (Natural Language Generation)
# ============================================================================

def generate_friendly_message(message_type, **kwargs):
    """ì¹œì ˆí•œ ìì—°ì–´ ë©”ì‹œì§€ ìƒì„±"""

    templates = {
        # ì„±ê³¼ ìš”ì•½
        'performance_good': "ì´ë²ˆ ë‹¬ ì„±ê³¼ê°€ ì¢‹ì•„ìš”! ì „í™˜ìœ¨ {cvr}%ë¡œ ìˆœí•­ ì¤‘ ğŸ’ª",
        'performance_warning': "ë¶„ë°œí•´ì•¼ í•©ë‹ˆë‹¤! ì´íƒˆë¥  ë°©ì–´ê°€ ì‹œê¸‰í•´ìš” ğŸš¨",
        'performance_stable': "ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆì–´ìš”. ì´ëŒ€ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš” ğŸ‘",

        # í¼ë„ ì´íƒˆ ì•Œë¦¼
        'activation_low_paid': "ğŸš¨ [{channel}] ê´‘ê³ ë¹„ê°€ ìƒˆê³  ìˆì–´ìš”!\nê´‘ê³ ë¥¼ í´ë¦­í•œ 10ëª… ì¤‘ {drop_count}ëª…ì´ 3ì´ˆ ë§Œì— ë‚˜ê°‘ë‹ˆë‹¤.\nğŸ’¡ ê´‘ê³  ë¬¸êµ¬ì™€ ìƒì„¸í˜ì´ì§€ ë‚´ìš©ì´ ë‹¬ë¼ì„œ ê³ ê°ì´ ì‹¤ë§í–ˆì„ í™•ë¥ ì´ ë†’ì•„ìš”!",
        'activation_low_organic': "ğŸ¢ [{channel}] í˜ì´ì§€ê°€ ë„ˆë¬´ ëŠë¦°ê°€ìš”?\nê²€ìƒ‰í•´ì„œ ë“¤ì–´ì˜¨ ë¶„ë“¤ì€ ì°¸ì„ì„±ì´ ì—†ì–´ì„œ ë¡œë”©ì´ ê¸¸ë©´ ë°”ë¡œ ë‚˜ê°‘ë‹ˆë‹¤.\nğŸ’¡ ìƒì„¸í˜ì´ì§€ì˜ ê³ ìš©ëŸ‰ ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•´ì„œ ë¡œë”© ì†ë„ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”.",
        'cart_abandonment': "ğŸ›’ [{channel}] ë‹¤ ê³¨ë¼ë†“ê³  ë§ì„¤ì´ê³  ìˆì–´ìš”!\nì¥ë°”êµ¬ë‹ˆê¹Œì§€ ì˜¨ ê³ ê°ì˜ {abandon_rate:.1f}%ê°€ ê²°ì œ ì—†ì´ ì´íƒˆí–ˆìŠµë‹ˆë‹¤.\nğŸ’¡ ë°°ì†¡ë¹„ê°€ ë¹„ì‹¸ê±°ë‚˜, íšŒì›ê°€ì…ì´ ê·€ì°®ì•„ì„œ ê·¸ëŸ´ ìˆ˜ ìˆì–´ìš”. ì´íƒˆ ì‹œì ì— 'ì²« êµ¬ë§¤ ë¬´ë£Œë°°ì†¡' íŒì—…ì„ ë„ì›Œë³´ì„¸ìš”.",

        # ì´íƒˆ/ê°œì„  ì˜ˆì¸¡
        'churn_warning': "ğŸ“‰ [{stage}] ì§€ë‚œì£¼ë³´ë‹¤ {change:.1f}% ì¤„ì—ˆì–´ìš”.\n{diagnosis}\nğŸ’¡ {action}",
        'improvement_notice': "ğŸ“ˆ [{stage}] ì§€ë‚œì£¼ë³´ë‹¤ {change:.1f}% ëŠ˜ì—ˆì–´ìš”! ğŸ‰\ní˜„ì¬ ì „ëµì´ íš¨ê³¼ë¥¼ ë³´ê³  ìˆìŠµë‹ˆë‹¤. ê³„ì† ìœ ì§€í•˜ì„¸ìš”!",

        # A/B í…ŒìŠ¤íŠ¸
        'ab_winner': "ğŸ‰ [{winner}] ì±„ë„ íš¨ìœ¨ì´ ì••ë„ì ìœ¼ë¡œ ì¢‹ìŠµë‹ˆë‹¤!\nì „í™˜ìœ¨ì´ {diff:.1f}%p ë” ë†’ìŠµë‹ˆë‹¤.\nğŸ’° ë§Œì•½ [{loser}] ëŒ€ì‹  [{winner}]ì— ì§‘ì¤‘í–ˆë‹¤ë©´, ì•½ {potential}ì„ ë” ë²Œì—ˆì„ ê±°ì˜ˆìš”.",
        'ab_no_difference': "ë‘ ì±„ë„ ê°„ ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ì—†ì–´ìš”. ì¢€ ë” ì§€ì¼œë´ì•¼ í•©ë‹ˆë‹¤ ğŸ”",

        # í´ëŸ¬ìŠ¤í„°ë§
        'cluster_high': "ğŸ† ê³ ì„±ê³¼ ê·¸ë£¹: {channels}\nì´ ì±„ë„ë“¤ì´ ë§¤ì¶œì˜ í•µì‹¬ì´ì—ìš”!",
        'cluster_mid': "ğŸ“Š ì„±ì¥ ê°€ëŠ¥ ê·¸ë£¹: {channels}\nì ì¬ë ¥ì´ ìˆì–´ìš”. íˆ¬ìë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.",
        'cluster_low': "âš ï¸ ê°œì„  í•„ìš” ê·¸ë£¹: {channels}\níš¨ìœ¨ì´ ë‚®ì•„ìš”. ì „ëµ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.",

        # ë°ì´í„° ë¶€ì¡±
        'insufficient_data': "ğŸ˜… {reason}\n{detail}"
    }

    template = templates.get(message_type, message_type)
    try:
        return template.format(**kwargs)
    except KeyError:
        return template


def generate_alert_message(alert_type, channel, rate, thresholds):
    """ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±"""

    if alert_type == 'activation_low':
        if 'Paid' in channel or 'Display' in channel or 'CPC' in channel:
            return {
                'severity': 'high',
                'title': f"ğŸš¨ [{channel}] ê´‘ê³ ë¹„ê°€ ìƒˆê³  ìˆì–´ìš”!",
                'message': f"ê´‘ê³ ë¥¼ í´ë¦­í•œ 10ëª… ì¤‘ {10 - int(rate/10)}ëª…ì´ 3ì´ˆ ë§Œì— ë‚˜ê°‘ë‹ˆë‹¤.",
                'reason': "ê´‘ê³  ë¬¸êµ¬ì™€ ìƒì„¸í˜ì´ì§€ ë‚´ìš©ì´ ë‹¬ë¼ì„œ ê³ ê°ì´ ì‹¤ë§í–ˆì„ í™•ë¥  90%!",
                'action': "ê´‘ê³  ì†Œì¬ì™€ ëœë”©í˜ì´ì§€ ì²« í™”ë©´ì´ ì¼ì¹˜í•˜ëŠ”ì§€ ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ì„¸ìš”.",
                'technical': f"ìœ ì…â†’í™œë™ ì „í™˜ìœ¨ì´ {rate:.1f}%ë¡œ ê¸°ì¤€({thresholds['activation_rate_warning']}%) ë¯¸ë‹¬"
            }
        else:
            return {
                'severity': 'medium',
                'title': f"ğŸ¢ [{channel}] í˜ì´ì§€ê°€ ë„ˆë¬´ ëŠë¦°ê°€ìš”?",
                'message': "ê²€ìƒ‰í•´ì„œ ë“¤ì–´ì˜¨ ë¶„ë“¤ì€ ì°¸ì„ì„±ì´ ì—†ì–´ì„œ ë¡œë”©ì´ ê¸¸ë©´ ë°”ë¡œ ë‚˜ê°‘ë‹ˆë‹¤.",
                'reason': "í˜ì´ì§€ ë¡œë”© ì†ë„ë‚˜ ì²« í™”ë©´ ì½˜í…ì¸  ë¬¸ì œì¼ ìˆ˜ ìˆì–´ìš”.",
                'action': "ìƒì„¸í˜ì´ì§€ì˜ ê³ ìš©ëŸ‰ ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•´ì„œ ë¡œë”© ì†ë„ë¥¼ ë†’ì—¬ì£¼ì„¸ìš”.",
                'technical': f"ìœ ì…â†’í™œë™ ì „í™˜ìœ¨ì´ {rate:.1f}%ë¡œ ê¸°ì¤€({thresholds['activation_rate_warning']}%) ë¯¸ë‹¬"
            }

    elif alert_type == 'cart_abandonment':
        return {
            'severity': 'high',
            'title': f"ğŸ›’ [{channel}] ë‹¤ ê³¨ë¼ë†“ê³  ë§ì„¤ì´ê³  ìˆì–´ìš”!",
            'message': f"ì¥ë°”êµ¬ë‹ˆê¹Œì§€ ì˜¨ ê³ ê°ì˜ {100-rate:.1f}%ê°€ ê²°ì œ ì—†ì´ ì´íƒˆí–ˆìŠµë‹ˆë‹¤.",
            'reason': "ë°°ì†¡ë¹„ê°€ ë¹„ì‹¸ê±°ë‚˜, íšŒì›ê°€ì…ì´ ê·€ì°®ì•„ì„œ ê·¸ëŸ´ ìˆ˜ ìˆì–´ìš”.",
            'action': "ì´íƒˆ ì‹œì ì— 'ì²« êµ¬ë§¤ ë¬´ë£Œë°°ì†¡' íŒì—…ì„ ë„ì›Œë³´ì„¸ìš”.",
            'technical': f"ê´€ì‹¬â†’êµ¬ë§¤ ì „í™˜ìœ¨ì´ {rate:.1f}%ë¡œ ê¸°ì¤€({thresholds['cart_conversion_warning']}%) ë¯¸ë‹¬"
        }

    return None


def generate_churn_message(stage, change_pct, thresholds):
    """ì´íƒˆ ì˜ˆì¸¡ ë©”ì‹œì§€ ìƒì„±"""
    recipe = CRM_RECIPES.get(stage, CRM_RECIPES['ìœ ì…'])
    friendly_stage = FRIENDLY_NAMES.get(stage, stage)

    risk_level = 'high' if change_pct < thresholds['high_risk_threshold'] else 'medium'

    return {
        'stage': stage,
        'stage_friendly': friendly_stage,
        'risk_level': risk_level,
        'change_pct': round(change_pct, 2),
        'trend_message': f"ğŸ“‰ ì§€ë‚œì£¼ë³´ë‹¤ {abs(change_pct):.1f}% ì¤„ì—ˆì–´ìš”.",
        'diagnosis': recipe['diagnosis'],
        'action': recipe['action'],
        'technical': recipe['technical']
    }


def generate_improvement_message(stage, change_pct, thresholds):
    """ì„±ê³¼ ê°œì„  ë©”ì‹œì§€ ìƒì„±"""
    friendly_stage = FRIENDLY_NAMES.get(stage, stage)

    improvement_level = 'high' if change_pct > thresholds['high_improvement_threshold'] else 'medium'

    return {
        'stage': stage,
        'stage_friendly': friendly_stage,
        'improvement_level': improvement_level,
        'change_pct': round(change_pct, 2),
        'trend_message': f"ğŸ“ˆ ì§€ë‚œì£¼ë³´ë‹¤ {change_pct:.1f}% ëŠ˜ì—ˆì–´ìš”! ğŸ‰",
        'message': "í˜„ì¬ ì „ëµì´ íš¨ê³¼ë¥¼ ë³´ê³  ìˆìŠµë‹ˆë‹¤. ê³„ì† ìœ ì§€í•˜ì„¸ìš”!",
        'action': f"{friendly_stage} ë‹¨ê³„ì˜ ì„±ê³¼ê°€ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆì‚° í™•ëŒ€ë¥¼ ê²€í† í•˜ì„¸ìš”."
    }


# ============================================================================
# 4. ë¶„ì„ ëª¨ë“ˆ (Analysis Modules)
# ============================================================================

def analyze_bcg_matrix(channel_funnel_pivot, thresholds):
    """
    ì±„ë„ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤ ë¶„ì„ (BCG Matrix ì‘ìš©)
    Traffic(ê·œëª¨) vs Efficiency(íš¨ìœ¨)ë¡œ 4ì‚¬ë¶„ë©´ ë¶„ë¥˜
    """
    if channel_funnel_pivot.empty:
        return {'status': 'insufficient_data', 'message': INSUFFICIENT_DATA_MESSAGES['few_channels']}

    results = {}

    # ì „ì²´ í‰ê·  ê³„ì‚°
    avg_traffic = channel_funnel_pivot['ìœ ì…'].mean() if 'ìœ ì…' in channel_funnel_pivot.columns else 0
    avg_cvr = channel_funnel_pivot['CVR'].mean() if 'CVR' in channel_funnel_pivot.columns else 0

    for _, row in channel_funnel_pivot.iterrows():
        channel = row['channel']
        traffic = row.get('ìœ ì…', 0)
        cvr = row.get('CVR', 0)
        revenue = row.get('Revenue', 0)

        # 4ì‚¬ë¶„ë©´ ë¶„ë¥˜
        if traffic >= avg_traffic and cvr >= avg_cvr:
            matrix_type = 'cash_cow'
        elif traffic < avg_traffic and cvr >= avg_cvr:
            matrix_type = 'hidden_gem'
        elif traffic >= avg_traffic and cvr < avg_cvr:
            matrix_type = 'money_pit'
        else:
            matrix_type = 'dog'

        bcg_info = BCG_MATRIX[matrix_type]

        results[channel] = {
            'stats': {
                'users': int(traffic),
                'users_formatted': format_number(traffic),
                'cvr': round(cvr, 2),
                'revenue': float(revenue),
                'revenue_formatted': format_korean_currency(revenue)
            },
            'bcg_matrix': {
                'quadrant': matrix_type,
                'type': bcg_info['type'],
                'icon': bcg_info['icon'],
                'message': bcg_info['message'],
                'action': bcg_info['action']
            }
        }

    return {
        'status': 'success',
        'avg_traffic': int(avg_traffic),
        'avg_cvr': round(avg_cvr, 2),
        'channels': results
    }


def analyze_contextual_alerts(df, channel_funnel_pivot, thresholds):
    """
    ìƒí™©(Context) ì¸ì‹í˜• ê²½ê³  ìƒì„±
    ì±„ë„ íŠ¹ì„±ì— ë”°ë¥¸ ì›ì¸ ì¶”ë¡ 
    """
    alerts = []

    for _, row in channel_funnel_pivot.iterrows():
        channel = row['channel']
        users = row.get('ìœ ì…', 0)

        if users < thresholds['min_users_for_analysis']:
            continue

        activation = row.get('í™œë™', 0)
        consideration = row.get('ê´€ì‹¬', 0)
        purchase = row.get('êµ¬ë§¤ì™„ë£Œ', 0)

        act_rate = safe_division(activation, users)
        cart_to_pay_rate = safe_division(purchase, consideration)

        # 1. ìœ ì…â†’í™œë™ ì „í™˜ìœ¨ ì²´í¬
        if act_rate < thresholds['activation_rate_warning']:
            alert = generate_alert_message('activation_low', channel, act_rate, thresholds)
            if alert:
                alerts.append(alert)

        # 2. ê´€ì‹¬â†’êµ¬ë§¤ ì „í™˜ìœ¨ ì²´í¬
        if consideration > 50 and cart_to_pay_rate < thresholds['cart_conversion_warning']:
            alert = generate_alert_message('cart_abandonment', channel, cart_to_pay_rate, thresholds)
            if alert:
                alerts.append(alert)

    return alerts


def analyze_ab_with_revenue_impact(channel_funnel_pivot, thresholds):
    """
    A/B í…ŒìŠ¤íŠ¸ ë° ë§¤ì¶œ ì„íŒ©íŠ¸ ë¶„ì„
    í†µê³„ì  ìœ ì˜ì„± + ëˆìœ¼ë¡œ í™˜ì‚°
    """
    ab_results = []
    revenue_insights = []

    if len(channel_funnel_pivot) < 2:
        return ab_results, [{'status': 'insufficient_data', 'message': INSUFFICIENT_DATA_MESSAGES['few_channels']}]

    channels = channel_funnel_pivot['channel'].values

    for i, ch_a in enumerate(channels):
        for ch_b in channels[i+1:]:
            try:
                row_a = channel_funnel_pivot[channel_funnel_pivot['channel'] == ch_a].iloc[0]
                row_b = channel_funnel_pivot[channel_funnel_pivot['channel'] == ch_b].iloc[0]

                users_a = row_a.get('ìœ ì…', 0)
                conv_a = row_a.get('êµ¬ë§¤ì™„ë£Œ', 0)
                rev_a = row_a.get('Revenue', 0)

                users_b = row_b.get('ìœ ì…', 0)
                conv_b = row_b.get('êµ¬ë§¤ì™„ë£Œ', 0)
                rev_b = row_b.get('Revenue', 0)

                # ì¹´ì´ì œê³± ê²€ì •
                contingency_table = np.array([
                    [conv_a, users_a - conv_a],
                    [conv_b, users_b - conv_b]
                ])

                if contingency_table.min() < thresholds['min_sample_size']:
                    continue

                chi2, p_value, _, _ = stats.chi2_contingency(contingency_table)

                cvr_a = safe_division(conv_a, users_a)
                cvr_b = safe_division(conv_b, users_b)

                is_significant = bool(p_value < thresholds['ab_significance'])

                ab_result = {
                    'type': 'channel_comparison',
                    'group_a': ch_a,
                    'group_b': ch_b,
                    'metric': 'conversion_rate',
                    'chi2_statistic': float(chi2),
                    'p_value': float(p_value),
                    'significant': is_significant,
                    'cvr_a': round(float(cvr_a), 2),
                    'cvr_b': round(float(cvr_b), 2)
                }

                # ìœ ì˜ë¯¸í•œ ê²½ìš° ë§¤ì¶œ ì„íŒ©íŠ¸ ê³„ì‚°
                if is_significant:
                    winner = ch_a if cvr_a > cvr_b else ch_b
                    loser = ch_b if cvr_a > cvr_b else ch_a
                    cvr_diff = abs(cvr_a - cvr_b) / 100

                    # í‰ê·  ê°ë‹¨ê°€
                    total_conv = conv_a + conv_b
                    total_rev = rev_a + rev_b
                    arpu = total_rev / total_conv if total_conv > 0 else 0

                    # ì ì¬ ë§¤ì¶œ
                    loser_users = users_b if cvr_a > cvr_b else users_a
                    potential_revenue = loser_users * cvr_diff * arpu

                    if potential_revenue > thresholds['potential_uplift_min']:
                        revenue_insights.append({
                            'test_pair': f"{ch_a} vs {ch_b}",
                            'winner': winner,
                            'loser': loser,
                            'message': f"ğŸ‰ [{winner}] ì±„ë„ íš¨ìœ¨ì´ ì••ë„ì ìœ¼ë¡œ ì¢‹ìŠµë‹ˆë‹¤!",
                            'detail': f"ì „í™˜ìœ¨ì´ {abs(cvr_a-cvr_b):.1f}%p ë” ë†’ìŠµë‹ˆë‹¤.",
                            'impact': f"ğŸ’° ë§Œì•½ [{loser}] ëŒ€ì‹  [{winner}]ì— ì§‘ì¤‘í–ˆë‹¤ë©´, ì•½ {format_korean_currency(potential_revenue)}ì„ ë” ë²Œì—ˆì„ ê±°ì˜ˆìš”.",
                            'potential_revenue': potential_revenue,
                            'potential_revenue_formatted': format_korean_currency(potential_revenue),
                            'action': f"ì´ì œ ê³ ë¯¼ ë! [{winner}] ìŠ¤íƒ€ì¼ì˜ ì „ëµì„ í™•ëŒ€ ì ìš©í•˜ì„¸ìš”."
                        })

                ab_results.append(ab_result)

            except Exception as e:
                continue

    return ab_results, revenue_insights


def analyze_kmeans_clustering(channel_funnel_pivot, thresholds):
    """K-Means í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì±„ë„ ê·¸ë£¹í™”"""

    if len(channel_funnel_pivot) < 3:
        return {
            'status': 'insufficient_data',
            'message': INSUFFICIENT_DATA_MESSAGES['few_channels']
        }

    try:
        clustering_features = []
        channel_names = []

        for _, row in channel_funnel_pivot.iterrows():
            total_acquisition = row.get('ìœ ì…', 0)
            if total_acquisition > 0:
                features = [
                    row.get('í™œë™', 0) / total_acquisition,
                    row.get('ê´€ì‹¬', 0) / total_acquisition,
                    row.get('ê²°ì œì§„í–‰', 0) / total_acquisition,
                    row.get('êµ¬ë§¤ì™„ë£Œ', 0) / total_acquisition,
                    row.get('CVR', 0) / 100,
                    row.get('Revenue', 0) / total_acquisition
                ]
                clustering_features.append(features)
                channel_names.append(row['channel'])

        if len(clustering_features) < 3:
            return {
                'status': 'insufficient_data',
                'message': INSUFFICIENT_DATA_MESSAGES['few_channels']
            }

        X = np.array(clustering_features)
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        n_clusters = min(3, len(channel_names))
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X_scaled)

        # í´ëŸ¬ìŠ¤í„°ë³„ í‰ê·  ì„±ê³¼ë¡œ ìˆœìœ„ ê²°ì •
        cluster_performance = {}
        for i in range(n_clusters):
            cluster_indices = [j for j, label in enumerate(cluster_labels) if label == i]
            avg_performance = np.mean([clustering_features[j][4] for j in cluster_indices])  # CVR ê¸°ì¤€
            cluster_performance[i] = avg_performance

        # ì„±ê³¼ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_clusters = sorted(cluster_performance.items(), key=lambda x: x[1], reverse=True)
        cluster_rank = {old: new for new, (old, _) in enumerate(sorted_clusters)}

        # í´ëŸ¬ìŠ¤í„°ë³„ ì±„ë„ ê·¸ë£¹í™”
        clusters = {'high': [], 'mid': [], 'low': []}
        cluster_labels_map = {0: 'high', 1: 'mid', 2: 'low'}

        for channel, label in zip(channel_names, cluster_labels):
            new_label = cluster_rank[label]
            group = cluster_labels_map.get(new_label, 'mid')
            clusters[group].append(channel)

        return {
            'status': 'success',
            'n_clusters': n_clusters,
            'clusters': clusters,
            'description': {
                'high': 'ğŸ† ê³ ì„±ê³¼ ê·¸ë£¹ - ì´ ì±„ë„ë“¤ì´ ë§¤ì¶œì˜ í•µì‹¬ì´ì—ìš”!',
                'mid': 'ğŸ“Š ì„±ì¥ ê°€ëŠ¥ ê·¸ë£¹ - ì ì¬ë ¥ì´ ìˆì–´ìš”. íˆ¬ìë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.',
                'low': 'âš ï¸ ê°œì„  í•„ìš” ê·¸ë£¹ - íš¨ìœ¨ì´ ë‚®ì•„ìš”. ì „ëµ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            },
            'recommendations': {
                'high': 'í˜„ì¬ íˆ¬ì ìˆ˜ì¤€ ìœ ì§€ ë° ëª¨ë‹ˆí„°ë§',
                'mid': 'ì„±ê³¼ ê°œì„  ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸ - ì˜ˆì‚° 10% ì¦ì•¡',
                'low': 'íš¨ìœ¨ ë¶„ì„ í›„ ì˜ˆì‚° ì¬ë°°ë¶„ ê²€í† '
            }
        }

    except Exception as e:
        return {
            'status': 'error',
            'message': f"í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }


def analyze_churn_and_improvement(daily_funnel_pivot, thresholds):
    """ì´íƒˆ ì˜ˆì¸¡ ë° ì„±ê³¼ ê°œì„  ë¶„ì„ (7ì¼ & 30ì¼)"""

    results = {
        'churn_7d': [],
        'churn_30d': [],
        'improvement_7d': [],
        'improvement_30d': [],
        'crm_actions': []
    }

    if len(daily_funnel_pivot) < 14:
        results['status'] = 'insufficient_data'
        results['message'] = INSUFFICIENT_DATA_MESSAGES['few_days']
        return results

    for stage in ['ìœ ì…', 'í™œë™', 'ê´€ì‹¬', 'ê²°ì œì§„í–‰']:
        if stage not in daily_funnel_pivot.columns:
            continue

        # 7ì¼ ë¹„êµ
        if len(daily_funnel_pivot) >= 14:
            recent_7d = daily_funnel_pivot[stage].tail(7).mean()
            previous_7d = daily_funnel_pivot[stage].iloc[-14:-7].mean()

            if previous_7d > 0:
                change_pct = ((recent_7d - previous_7d) / previous_7d) * 100

                if change_pct < thresholds['churn_alert_threshold']:
                    churn_msg = generate_churn_message(stage, change_pct, thresholds)
                    churn_msg['period'] = '7d'
                    churn_msg['recent_avg'] = round(recent_7d, 2)
                    churn_msg['previous_avg'] = round(previous_7d, 2)
                    results['churn_7d'].append(churn_msg)

                    # CRM ì•¡ì…˜ ì¶”ê°€
                    results['crm_actions'].append({
                        'stage': FRIENDLY_NAMES.get(stage, stage),
                        'trend': f"ğŸ“‰ ì§€ë‚œì£¼ë³´ë‹¤ {abs(change_pct):.1f}% ì¤„ì—ˆì–´ìš”.",
                        'diagnosis': CRM_RECIPES.get(stage, CRM_RECIPES['ìœ ì…'])['diagnosis'],
                        'prescription': CRM_RECIPES.get(stage, CRM_RECIPES['ìœ ì…'])['action']
                    })

                elif change_pct > thresholds['improvement_threshold']:
                    improvement_msg = generate_improvement_message(stage, change_pct, thresholds)
                    improvement_msg['period'] = '7d'
                    improvement_msg['recent_avg'] = round(recent_7d, 2)
                    improvement_msg['previous_avg'] = round(previous_7d, 2)
                    results['improvement_7d'].append(improvement_msg)

        # 30ì¼ ë¹„êµ
        if len(daily_funnel_pivot) >= 60:
            recent_30d = daily_funnel_pivot[stage].tail(30).mean()
            previous_30d = daily_funnel_pivot[stage].iloc[-60:-30].mean()

            if previous_30d > 0:
                change_pct = ((recent_30d - previous_30d) / previous_30d) * 100

                if change_pct < thresholds['churn_alert_threshold']:
                    churn_msg = generate_churn_message(stage, change_pct, thresholds)
                    churn_msg['period'] = '30d'
                    churn_msg['recent_avg'] = round(recent_30d, 2)
                    churn_msg['previous_avg'] = round(previous_30d, 2)
                    results['churn_30d'].append(churn_msg)

                elif change_pct > thresholds['improvement_threshold']:
                    improvement_msg = generate_improvement_message(stage, change_pct, thresholds)
                    improvement_msg['period'] = '30d'
                    improvement_msg['recent_avg'] = round(recent_30d, 2)
                    improvement_msg['previous_avg'] = round(previous_30d, 2)
                    results['improvement_30d'].append(improvement_msg)

    results['status'] = 'success'
    return results


# ============================================================================
# 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Main Executor)
# ============================================================================

def generate_funnel_insights(category='default', ga4_file=None):
    """í¼ë„ ì¸ì‚¬ì´íŠ¸ ìƒì„± ë©”ì¸ í•¨ìˆ˜"""

    print("ğŸš€ í¼ë„ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"   ì¹´í…Œê³ ë¦¬: {category}")

    # ì„ê³„ê°’ ë¡œë“œ
    thresholds = get_thresholds(category)
    print(f"   ì„ê³„ê°’ í”„ë¦¬ì…‹: {category}")

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    FUNNEL_DIR.mkdir(parents=True, exist_ok=True)

    # ë°ì´í„° ë¡œë“œ
    if ga4_file is None:
        ga4_file = GA4_DIR / 'GA4_data.csv'

    if not os.path.exists(ga4_file):
        print(f"âŒ {INSUFFICIENT_DATA_MESSAGES['no_file']}")
        print(f"   ê²½ë¡œ: {ga4_file}")

        # ë¹ˆ ì¸ì‚¬ì´íŠ¸ ì €ì¥
        empty_insights = {
            'status': 'no_data',
            'message': INSUFFICIENT_DATA_MESSAGES['no_file'],
            'generated_at': datetime.now().isoformat()
        }
        with open(FUNNEL_DIR / 'insights.json', 'w', encoding='utf-8') as f:
            json.dump(empty_insights, f, ensure_ascii=False, indent=2)
        return empty_insights

    print(f"   ë°ì´í„° íŒŒì¼: {ga4_file}")

    df = pd.read_csv(ga4_file, encoding='utf-8-sig')
    df['Day'] = pd.to_datetime(df['Day'])
    if 'week' in df.columns:
        df['week'] = pd.to_datetime(df['week'])

    # ë°ì´í„° ì¶©ë¶„ì„± ì²´í¬
    data_issues = check_data_sufficiency(df, thresholds)
    if any(issue['type'] in ['empty_data', 'no_conversion'] for issue in data_issues):
        print(f"âš ï¸ {data_issues[0]['message']}")

    # ========================================
    # CSV íŒŒì¼ ìƒì„±
    # ========================================
    print("\nğŸ“Š CSV íŒŒì¼ ìƒì„± ì¤‘...")

    # 1. ì¼ë³„ í¼ë„
    daily_funnel = df.groupby(['Day', 'funnel']).agg({
        'Total users': 'sum',
        'New users': 'sum',
        'Event count': 'sum',
        'Event value': 'sum',
        'Sessions': 'sum'
    }).reset_index()

    daily_funnel_pivot = daily_funnel.pivot_table(
        index='Day', columns='funnel', values='Total users',
        aggfunc='sum', fill_value=0
    ).reset_index()

    existing_cols = [col for col in FUNNEL_ORDER if col in daily_funnel_pivot.columns]
    daily_funnel_pivot = daily_funnel_pivot[['Day'] + existing_cols]

    if 'ìœ ì…' in daily_funnel_pivot.columns and 'êµ¬ë§¤ì™„ë£Œ' in daily_funnel_pivot.columns:
        daily_funnel_pivot['CVR'] = (daily_funnel_pivot['êµ¬ë§¤ì™„ë£Œ'] / daily_funnel_pivot['ìœ ì…'] * 100).fillna(0)

    daily_funnel_pivot.to_csv(FUNNEL_DIR / 'daily_funnel.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ“ ì¼ë³„ í¼ë„: {len(daily_funnel_pivot)} rows")

    # 2. ì£¼ë³„ í¼ë„
    if 'week' in df.columns:
        weekly_funnel = df.groupby(['week', 'funnel']).agg({
            'Total users': 'sum', 'New users': 'sum',
            'Event count': 'sum', 'Event value': 'sum'
        }).reset_index()

        weekly_funnel_pivot = weekly_funnel.pivot_table(
            index='week', columns='funnel', values='Total users',
            aggfunc='sum', fill_value=0
        ).reset_index()

        existing_cols_weekly = [col for col in FUNNEL_ORDER if col in weekly_funnel_pivot.columns]
        weekly_funnel_pivot = weekly_funnel_pivot[['week'] + existing_cols_weekly]

        if 'ìœ ì…' in weekly_funnel_pivot.columns and 'êµ¬ë§¤ì™„ë£Œ' in weekly_funnel_pivot.columns:
            weekly_funnel_pivot['CVR'] = (weekly_funnel_pivot['êµ¬ë§¤ì™„ë£Œ'] / weekly_funnel_pivot['ìœ ì…'] * 100).fillna(0)

        weekly_funnel_pivot.to_csv(FUNNEL_DIR / 'weekly_funnel.csv', index=False, encoding='utf-8-sig')
        print(f"   âœ“ ì£¼ë³„ í¼ë„: {len(weekly_funnel_pivot)} rows")

    # 3. ì±„ë„ë³„ í¼ë„
    channel_funnel = df.groupby(['channel', 'funnel']).agg({
        'Total users': 'sum', 'Event value': 'sum'
    }).reset_index()

    channel_funnel_pivot = channel_funnel.pivot_table(
        index='channel', columns='funnel', values='Total users',
        aggfunc='sum', fill_value=0
    ).reset_index()

    channel_revenue = df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ'].groupby('channel')['Event value'].sum().reset_index()
    channel_revenue.columns = ['channel', 'Revenue']

    channel_funnel_pivot = channel_funnel_pivot.merge(channel_revenue, on='channel', how='left')
    channel_funnel_pivot['Revenue'] = channel_funnel_pivot['Revenue'].fillna(0)

    if 'ìœ ì…' in channel_funnel_pivot.columns and 'êµ¬ë§¤ì™„ë£Œ' in channel_funnel_pivot.columns:
        channel_funnel_pivot['CVR'] = (channel_funnel_pivot['êµ¬ë§¤ì™„ë£Œ'] / channel_funnel_pivot['ìœ ì…'] * 100).fillna(0)

    channel_funnel_pivot.to_csv(FUNNEL_DIR / 'channel_funnel.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ“ ì±„ë„ë³„ í¼ë„: {len(channel_funnel_pivot)} rows")

    # 4. ìº í˜ì¸ë³„ í¼ë„
    campaign_funnel = df.groupby(['Session campaign', 'funnel']).agg({
        'Total users': 'sum', 'Event value': 'sum'
    }).reset_index()

    top_campaigns = df[df['funnel'] == 'ìœ ì…'].groupby('Session campaign')['Total users'].sum().nlargest(20).index
    campaign_funnel_top = campaign_funnel[campaign_funnel['Session campaign'].isin(top_campaigns)]

    campaign_funnel_pivot = campaign_funnel_top.pivot_table(
        index='Session campaign', columns='funnel', values='Total users',
        aggfunc='sum', fill_value=0
    ).reset_index()

    campaign_revenue = df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ'].groupby('Session campaign')['Event value'].sum().reset_index()
    campaign_revenue.columns = ['Session campaign', 'Revenue']

    campaign_funnel_pivot = campaign_funnel_pivot.merge(campaign_revenue, on='Session campaign', how='left')
    campaign_funnel_pivot['Revenue'] = campaign_funnel_pivot['Revenue'].fillna(0)

    if 'ìœ ì…' in campaign_funnel_pivot.columns and 'êµ¬ë§¤ì™„ë£Œ' in campaign_funnel_pivot.columns:
        campaign_funnel_pivot['CVR'] = (campaign_funnel_pivot['êµ¬ë§¤ì™„ë£Œ'] / campaign_funnel_pivot['ìœ ì…'] * 100).fillna(0)

    campaign_funnel_pivot.to_csv(FUNNEL_DIR / 'campaign_funnel.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ“ ìº í˜ì¸ë³„ í¼ë„: {len(campaign_funnel_pivot)} rows")

    # 5. ì‹ ê·œ vs ì¬ë°©ë¬¸
    new_vs_returning = df.groupby(['Day', 'funnel']).agg({
        'Total users': 'sum', 'New users': 'sum'
    }).reset_index()

    new_vs_returning['Returning users'] = new_vs_returning['Total users'] - new_vs_returning['New users']
    new_vs_returning['New user %'] = (new_vs_returning['New users'] / new_vs_returning['Total users'] * 100).fillna(0)

    new_vs_returning.to_csv(FUNNEL_DIR / 'new_vs_returning.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ“ ì‹ ê·œ/ì¬ë°©ë¬¸: {len(new_vs_returning)} rows")

    # ========================================
    # ì¸ì‚¬ì´íŠ¸ ìƒì„±
    # ========================================
    print("\nğŸ” ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì¤‘...")

    # ê¸°ë³¸ ìš”ì•½
    total_acquisition = int(df[df['funnel'] == 'ìœ ì…']['Total users'].sum())
    total_activation = int(df[df['funnel'] == 'í™œë™']['Total users'].sum())
    total_consideration = int(df[df['funnel'] == 'ê´€ì‹¬']['Total users'].sum())
    total_conversion = int(df[df['funnel'] == 'ê²°ì œì§„í–‰']['Total users'].sum())
    total_purchase = int(df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ']['Total users'].sum())
    total_revenue = float(df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ']['Event value'].sum())
    overall_cvr = safe_division(total_purchase, total_acquisition)

    start_date = df['Day'].min().strftime('%Y-%m-%d')
    end_date = df['Day'].max().strftime('%Y-%m-%d')

    # ì„±ê³¼ ë©”ì‹œì§€ ê²°ì •
    if overall_cvr > 3.0:
        status_message = generate_friendly_message('performance_good', cvr=f"{overall_cvr:.1f}")
    elif overall_cvr < 1.0:
        status_message = generate_friendly_message('performance_warning')
    else:
        status_message = generate_friendly_message('performance_stable')

    # ìƒìœ„ ì±„ë„/ìº í˜ì¸
    top_channels = []
    channel_summary = df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ'].groupby('channel').agg({
        'Total users': 'sum', 'Event value': 'sum'
    }).reset_index().nlargest(5, 'Event value')

    for _, row in channel_summary.iterrows():
        top_channels.append({
            'name': row['channel'],
            'purchases': int(row['Total users']),
            'revenue': float(row['Event value']),
            'revenue_formatted': format_korean_currency(row['Event value'])
        })

    top_campaigns_list = []
    campaign_summary = df[df['funnel'] == 'êµ¬ë§¤ì™„ë£Œ'].groupby('Session campaign').agg({
        'Total users': 'sum', 'Event value': 'sum'
    }).reset_index().nlargest(5, 'Event value')

    for _, row in campaign_summary.iterrows():
        top_campaigns_list.append({
            'name': row['Session campaign'],
            'purchases': int(row['Total users']),
            'revenue': float(row['Event value']),
            'revenue_formatted': format_korean_currency(row['Event value'])
        })

    # ê° ë¶„ì„ ëª¨ë“ˆ ì‹¤í–‰
    print("   - BCG Matrix ë¶„ì„...")
    bcg_analysis = analyze_bcg_matrix(channel_funnel_pivot, thresholds)

    print("   - ìƒí™© ì¸ì‹í˜• ì•Œë¦¼ ìƒì„±...")
    contextual_alerts = analyze_contextual_alerts(df, channel_funnel_pivot, thresholds)

    print("   - A/B í…ŒìŠ¤íŠ¸ & ë§¤ì¶œ ì„íŒ©íŠ¸...")
    ab_results, revenue_insights = analyze_ab_with_revenue_impact(channel_funnel_pivot, thresholds)

    print("   - K-Means í´ëŸ¬ìŠ¤í„°ë§...")
    kmeans_result = analyze_kmeans_clustering(channel_funnel_pivot, thresholds)

    print("   - ì´íƒˆ/ê°œì„  ì˜ˆì¸¡...")
    churn_analysis = analyze_churn_and_improvement(daily_funnel_pivot, thresholds)

    # ê¸°ë³¸ í¼ë„ ê²½ê³  (ì›ë³¸ ìœ ì§€)
    basic_alerts = []
    funnel_totals = df.groupby('funnel')['Total users'].sum()

    if 'ìœ ì…' in funnel_totals.index and 'í™œë™' in funnel_totals.index:
        activation_rate = funnel_totals['í™œë™'] / funnel_totals['ìœ ì…'] * 100
        if activation_rate < thresholds['activation_rate_warning']:
            basic_alerts.append({
                'type': 'low_activation',
                'message': f"ìœ ì…â†’í™œë™ ì „í™˜ìœ¨ì´ {activation_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ëœë”©í˜ì´ì§€ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                'message_friendly': f"ğŸ˜… ë°©ë¬¸ìì˜ {100-activation_rate:.0f}%ê°€ êµ¬ê²½ë„ ì•ˆ í•˜ê³  ë‚˜ê°€ìš”!",
                'severity': 'high'
            })

    if 'ê´€ì‹¬' in funnel_totals.index and 'êµ¬ë§¤ì™„ë£Œ' in funnel_totals.index:
        cart_rate = funnel_totals['êµ¬ë§¤ì™„ë£Œ'] / funnel_totals['ê´€ì‹¬'] * 100
        if cart_rate < thresholds['cart_conversion_warning']:
            basic_alerts.append({
                'type': 'low_consideration_conversion',
                'message': f"ì¥ë°”êµ¬ë‹ˆâ†’êµ¬ë§¤ ì „í™˜ìœ¨ì´ {cart_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ê²°ì œ í”„ë¡œì„¸ìŠ¤ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                'message_friendly': f"ğŸ›’ ì¥ë°”êµ¬ë‹ˆì— ë‹´ì€ ê³ ê°ì˜ {100-cart_rate:.0f}%ê°€ êµ¬ë§¤ë¥¼ í¬ê¸°í–ˆì–´ìš”!",
                'severity': 'medium'
            })

    # ========================================
    # ìµœì¢… JSON êµ¬ì¡° ì¡°ë¦½
    # ========================================
    insights = {
        'generated_at': datetime.now().isoformat(),
        'category': category,
        'thresholds_used': thresholds,

        # ë©”íƒ€ ì •ë³´ (ì¹œì ˆí•œ ë²„ì „)
        'meta': {
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'analysis_period': f"{start_date} ~ {end_date}",
            'category': category
        },

        # ìš”ì•½ ì¹´ë“œ (ì¹œì ˆí•œ ë²„ì „)
        'summary_card': {
            'title': 'ì´ë²ˆ ë‹¬ ì„±ê³¼ ìš”ì•½',
            'revenue_text': format_korean_currency(total_revenue),
            'cvr_text': f"{overall_cvr:.1f}%",
            'visitors_text': format_number(total_acquisition),
            'purchasers_text': format_number(total_purchase),
            'status_message': status_message
        },

        # ìš”ì•½ (ì›ë³¸ í˜¸í™˜)
        'summary': {
            'total_acquisition': total_acquisition,
            'total_activation': total_activation,
            'total_consideration': total_consideration,
            'total_conversion': total_conversion,
            'total_purchase': total_purchase,
            'total_revenue': total_revenue,
            'total_revenue_formatted': format_korean_currency(total_revenue),
            'overall_cvr': round(overall_cvr, 2)
        },

        # ì „ì²´ ê¸°ê°„ (ì›ë³¸ í˜¸í™˜)
        'overall': {
            'current_period': {
                'start_date': start_date,
                'end_date': end_date,
                'total_acquisition': total_acquisition,
                'total_activation': total_activation,
                'total_consideration': total_consideration,
                'total_conversion': total_conversion,
                'total_purchase': total_purchase,
                'total_revenue': total_revenue,
                'total_revenue_formatted': format_korean_currency(total_revenue),
                'overall_cvr': round(overall_cvr, 2)
            },
            'trend': {
                'direction': 'improving' if len(churn_analysis.get('improvement_7d', [])) > len(churn_analysis.get('churn_7d', [])) else
                             'declining' if len(churn_analysis.get('churn_7d', [])) > 0 else 'stable'
            }
        },

        # ìƒìœ„ ì±„ë„/ìº í˜ì¸
        'top_channels': top_channels,
        'top_campaigns': top_campaigns_list,

        # ì•Œë¦¼ (í†µí•©)
        'alerts': basic_alerts,
        'urgent_alerts': contextual_alerts,

        # BCG Matrix ë¶„ì„ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        'channel_strategy': bcg_analysis,

        # A/B í…ŒìŠ¤íŠ¸ (ì›ë³¸ + ë§¤ì¶œ ì„íŒ©íŠ¸)
        'ab_test_results': ab_results,
        'opportunity_spotlight': revenue_insights,

        # K-Means í´ëŸ¬ìŠ¤í„°ë§ (ì›ë³¸ í˜¸í™˜ + ê°œì„ )
        'channel_clusters': kmeans_result,

        # ì´íƒˆ/ê°œì„  ì˜ˆì¸¡ (ì›ë³¸ í˜¸í™˜)
        'churn_predictions_7d': churn_analysis.get('churn_7d', []),
        'churn_predictions_30d': churn_analysis.get('churn_30d', []),
        'improvement_predictions_7d': churn_analysis.get('improvement_7d', []),
        'improvement_predictions_30d': churn_analysis.get('improvement_30d', []),
        'churn_predictions': churn_analysis.get('churn_7d', []),  # í•˜ìœ„ í˜¸í™˜

        # CRM ì•¡ì…˜ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        'crm_actions': churn_analysis.get('crm_actions', []),

        # ë°ì´í„° ì´ìŠˆ
        'data_issues': data_issues,

        # ìƒì„¸ í†µê³„
        'details': {
            'total_channels': len(channel_funnel_pivot),
            'total_campaigns': len(campaign_funnel_pivot),
            'analysis_period_days': len(daily_funnel_pivot),
            'ab_tests_conducted': len(ab_results),
            'significant_ab_tests': len([t for t in ab_results if t.get('significant', False)]),
            'churn_risk_stages_7d': len(churn_analysis.get('churn_7d', [])),
            'churn_risk_stages_30d': len(churn_analysis.get('churn_30d', [])),
            'improvement_stages_7d': len(churn_analysis.get('improvement_7d', [])),
            'improvement_stages_30d': len(churn_analysis.get('improvement_30d', []))
        }
    }

    # JSON ì €ì¥ (numpy íƒ€ì… ë³€í™˜ ì ìš©)
    serializable_insights = convert_to_serializable(insights)
    with open(FUNNEL_DIR / 'insights.json', 'w', encoding='utf-8') as f:
        json.dump(serializable_insights, f, ensure_ascii=False, indent=2)

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("âœ… í¼ë„ ë¶„ì„ ì™„ë£Œ!")
    print("="*60)
    print(f"\nğŸ“Š ì„±ê³¼ ìš”ì•½:")
    print(f"   - ì´ ë°©ë¬¸ì: {format_number(total_acquisition)}ëª…")
    print(f"   - ì´ êµ¬ë§¤ì: {format_number(total_purchase)}ëª…")
    print(f"   - ì´ ë§¤ì¶œ: {format_korean_currency(total_revenue)}")
    print(f"   - ì „í™˜ìœ¨: {overall_cvr:.2f}%")
    print(f"\nğŸ“ˆ ê³ ê¸‰ ë¶„ì„:")
    print(f"   - A/B í…ŒìŠ¤íŠ¸: {len(ab_results)}ê°œ (ìœ ì˜ë¯¸: {len([t for t in ab_results if t.get('significant', False)])}ê°œ)")
    print(f"   - ì±„ë„ í´ëŸ¬ìŠ¤í„°: {kmeans_result.get('n_clusters', 0)}ê°œ ê·¸ë£¹")
    print(f"   - ì´íƒˆ ìœ„í—˜ (7ì¼): {len(churn_analysis.get('churn_7d', []))}ê°œ")
    print(f"   - ì„±ê³¼ ê°œì„  (7ì¼): {len(churn_analysis.get('improvement_7d', []))}ê°œ")
    print(f"   - ê¸´ê¸‰ ì•Œë¦¼: {len(contextual_alerts)}ê°œ")
    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"   - {FUNNEL_DIR / 'insights.json'}")
    print(f"   - {FUNNEL_DIR / 'daily_funnel.csv'}")
    print(f"   - {FUNNEL_DIR / 'weekly_funnel.csv'}")
    print(f"   - {FUNNEL_DIR / 'channel_funnel.csv'}")
    print(f"   - {FUNNEL_DIR / 'campaign_funnel.csv'}")
    print(f"   - {FUNNEL_DIR / 'new_vs_returning.csv'}")

    return insights


# ============================================================================
# 6. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
# ============================================================================

if __name__ == '__main__':
    import sys

    # ì¹´í…Œê³ ë¦¬ ì¸ì ì²˜ë¦¬ (ê¸°ë³¸ê°’: default)
    category = sys.argv[1] if len(sys.argv) > 1 else os.environ.get('BUSINESS_CATEGORY', 'default')

    # ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ì¶œë ¥
    if category == '--help' or category == '-h':
        print("ì‚¬ìš©ë²•: python generate_funnel_data.py [category]")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬:")
        for cat in CATEGORY_THRESHOLDS.keys():
            print(f"  - {cat}")
        print("\nì˜ˆì‹œ:")
        print("  python generate_funnel_data.py fashion")
        print("  python generate_funnel_data.py food")
        print("  python generate_funnel_data.py electronics")
        sys.exit(0)

    # ì¸ì‚¬ì´íŠ¸ ìƒì„±
    generate_funnel_insights(category=category)
