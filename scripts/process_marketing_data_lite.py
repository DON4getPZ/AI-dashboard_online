"""
ë§ˆì¼€íŒ… ë°ì´í„° ì „ì²˜ë¦¬ - ê²½ëŸ‰ ë²„ì „ (ë©”ëª¨ë¦¬ ì ˆì•½)

ê¸°ëŠ¥:
1. ì›ë³¸ CSV ë°ì´í„° ë¡œë“œ ë° ì •ì œ
2. ì›”ë³„ ë°ì´í„° ë¶„ë¦¬ ì €ì¥
3. í†µê³„ ë¶„ì„ (í‰ê· , í‘œì¤€í¸ì°¨, ì´ìƒì¹˜ íƒì§€)
4. ë‹¨ìˆœ ì˜ˆì¸¡ (Prophet ë¯¸ì‚¬ìš©, ë©”ëª¨ë¦¬ ì ˆì•½)
5. ë©”íƒ€ë°ì´í„° ìƒì„±

í™˜ê²½ë³€ìˆ˜:
- INPUT_CSV_PATH: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: raw_data.csv)
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
import warnings

# UTF-8 ì¶œë ¥ ì„¤ì • (Windows ì½˜ì†” í˜¸í™˜)
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

import pandas as pd
import numpy as np
from scipy import stats

warnings.filterwarnings('ignore')

# ë””ë ‰í† ë¦¬ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / 'data'
RAW_DIR = DATA_DIR / 'raw'
META_DIR = DATA_DIR / 'meta'
FORECAST_DIR = DATA_DIR / 'forecast'
STATS_DIR = DATA_DIR / 'statistics'

# ë””ë ‰í† ë¦¬ ìƒì„±
for dir_path in [RAW_DIR, META_DIR, FORECAST_DIR, STATS_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)


def load_and_clean_data(file_path: str) -> pd.DataFrame:
    """ì›ë³¸ CSV ë¡œë“œ ë° ê¸°ë³¸ ì •ì œ"""
    print("ğŸ“¥ ë°ì´í„° ë¡œë”© ì¤‘...")

    # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì½ê¸°
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(file_path, encoding='cp949')
        except:
            df = pd.read_csv(file_path, encoding='latin-1')

    print(f"   â”œ ë¡œë“œëœ í–‰ ìˆ˜: {len(df):,}")
    print(f"   â”œ ë¡œë“œëœ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")

    # ì»¬ëŸ¼ëª… ì •ë¦¬
    df.columns = df.columns.str.strip()

    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    missing_cols = [col for col in ['ì›” êµ¬ë¶„', 'ì¼ êµ¬ë¶„', 'ë¹„ìš©'] if col not in df.columns]
    if missing_cols:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_cols}")

    return df


def clean_and_convert_types(df: pd.DataFrame) -> pd.DataFrame:
    """ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    print("\nğŸ”§ ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘...")

    # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    df['ì¼ êµ¬ë¶„'] = pd.to_datetime(df['ì¼ êµ¬ë¶„'], errors='coerce')

    # ìˆ«ì ì»¬ëŸ¼ ë³€í™˜
    numeric_cols = ['ë¹„ìš©', 'ë…¸ì¶œ', 'í´ë¦­', 'ì „í™˜ìˆ˜', 'ì „í™˜ê°’']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # ë‚ ì§œê°€ ì—†ëŠ” í–‰ ì œê±°
    df = df.dropna(subset=['ì¼ êµ¬ë¶„'])

    print(f"   â”œ ì •ì œ í›„ í–‰ ìˆ˜: {len(df):,}")
    print(f"   â”” ë‚ ì§œ ë²”ìœ„: {df['ì¼ êµ¬ë¶„'].min()} ~ {df['ì¼ êµ¬ë¶„'].max()}")

    return df


def calculate_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """ë§ˆì¼€íŒ… ì§€í‘œ ê³„ì‚°"""
    print("\nğŸ“Š ë§ˆì¼€íŒ… ì§€í‘œ ê³„ì‚° ì¤‘...")

    # CTR, CPC, CPA, CVR, ROAS
    df['ctr'] = np.where(df['ë…¸ì¶œ'] > 0, (df['í´ë¦­'] / df['ë…¸ì¶œ'] * 100).round(2), 0)
    df['cpc'] = np.where(df['í´ë¦­'] > 0, (df['ë¹„ìš©'] / df['í´ë¦­']).round(0), 0)
    df['cpa'] = np.where(df['ì „í™˜ìˆ˜'] > 0, (df['ë¹„ìš©'] / df['ì „í™˜ìˆ˜']).round(0), 0)
    df['cvr'] = np.where(df['í´ë¦­'] > 0, (df['ì „í™˜ìˆ˜'] / df['í´ë¦­'] * 100).round(2), 0)
    df['roas'] = np.where(df['ë¹„ìš©'] > 0, (df['ì „í™˜ê°’'] / df['ë¹„ìš©'] * 100).round(0), 0)

    print(f"   âœ… ì§€í‘œ ê³„ì‚° ì™„ë£Œ")

    return df


def split_by_month(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """ì›”ë³„ë¡œ ë°ì´í„° ë¶„ë¦¬"""
    print("\nğŸ“… ì›”ë³„ ë°ì´í„° ë¶„ë¦¬ ì¤‘...")

    monthly_data = {}
    df['year_month'] = df['ì¼ êµ¬ë¶„'].dt.to_period('M')

    for period, group in df.groupby('year_month'):
        month_str = str(period)
        monthly_data[month_str] = group.copy()
        print(f"   â”œ {month_str}: {len(group):,}í–‰")

    return monthly_data


def save_monthly_csv(monthly_data: Dict[str, pd.DataFrame]) -> List[Dict]:
    """ì›”ë³„ CSV ì €ì¥"""
    print("\nğŸ’¾ ì›”ë³„ CSV ì €ì¥ ì¤‘...")

    month_info = []

    for month_str, df_month in monthly_data.items():
        df_save = df_month.drop(columns=['year_month'], errors='ignore')

        filename = f"{month_str}.csv"
        filepath = RAW_DIR / filename

        df_save.to_csv(filepath, index=False, encoding='utf-8')

        file_size = filepath.stat().st_size / 1024

        metrics = {
            'total_cost': float(df_month['ë¹„ìš©'].sum()),
            'total_impressions': int(df_month['ë…¸ì¶œ'].sum()),
            'total_clicks': int(df_month['í´ë¦­'].sum()),
            'total_conversions': int(df_month['ì „í™˜ìˆ˜'].sum()),
            'total_revenue': float(df_month['ì „í™˜ê°’'].sum())
        }

        month_info.append({
            'month': month_str,
            'filename': filename,
            'rows': len(df_month),
            'size_kb': round(file_size, 1),
            'date_range': {
                'start': df_month['ì¼ êµ¬ë¶„'].min().strftime('%Y-%m-%d'),
                'end': df_month['ì¼ êµ¬ë¶„'].max().strftime('%Y-%m-%d')
            },
            'metrics': metrics
        })

        print(f"   â”œ {filename} ({file_size:.1f} KB)")

    return month_info


def calculate_statistics(df: pd.DataFrame) -> Dict[str, Any]:
    """í†µê³„ ë¶„ì„"""
    print("\nğŸ“ˆ í†µê³„ ë¶„ì„ ì¤‘...")

    metrics = ['ë¹„ìš©', 'ë…¸ì¶œ', 'í´ë¦­', 'ì „í™˜ìˆ˜', 'ì „í™˜ê°’', 'ctr', 'cpc', 'cpa', 'cvr', 'roas']
    statistics = {}

    for metric in metrics:
        if metric not in df.columns:
            continue

        data = df[metric].replace([np.inf, -np.inf], np.nan).dropna()

        if len(data) == 0:
            continue

        mean_val = float(data.mean())
        median_val = float(data.median())
        std_val = float(data.std())

        statistics[metric] = {
            'mean': round(mean_val, 2),
            'median': round(median_val, 2),
            'std': round(std_val, 2),
            'min': round(float(data.min()), 2),
            'max': round(float(data.max()), 2),
            'q25': round(float(data.quantile(0.25)), 2),
            'q75': round(float(data.quantile(0.75)), 2)
        }

        print(f"   â”œ {metric}: í‰ê· ={mean_val:.1f}")

    stats_file = STATS_DIR / 'statistics.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(statistics, f, ensure_ascii=False, indent=2)

    print(f"   âœ… {stats_file.name} ì €ì¥ ì™„ë£Œ")

    return statistics


def simple_forecast(df: pd.DataFrame, days: int = 30) -> pd.DataFrame:
    """ìµœê·¼ 90ì¼ ë°ì´í„° ê¸°ë°˜ ë‹¨ìˆœ ì˜ˆì¸¡ (ì£¼ê°„ íŒ¨í„´ ë°˜ì˜)"""
    print(f"\nğŸ”® ì‹œê³„ì—´ ì˜ˆì¸¡ ì¤‘ ({days}ì¼, ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ)...")

    # ì¼ë³„ ì§‘ê³„
    daily = df.groupby('ì¼ êµ¬ë¶„').agg({
        'ë¹„ìš©': 'sum',
        'ë…¸ì¶œ': 'sum',
        'í´ë¦­': 'sum',
        'ì „í™˜ìˆ˜': 'sum',
        'ì „í™˜ê°’': 'sum'
    }).reset_index()

    daily = daily.sort_values('ì¼ êµ¬ë¶„')

    # ìµœê·¼ 90ì¼ ë°ì´í„° ì‚¬ìš©
    learning_period = min(90, len(daily))
    learning_data = daily.tail(learning_period).copy()

    print(f"   â”œ í•™ìŠµ ê¸°ê°„: ìµœê·¼ {learning_period}ì¼")

    metrics = ['ë¹„ìš©', 'ë…¸ì¶œ', 'í´ë¦­', 'ì „í™˜ìˆ˜', 'ì „í™˜ê°’']
    base_values = {}
    std_values = {}
    weekly_patterns = {}

    for metric in metrics:
        metric_data = learning_data[metric].copy()
        threshold = metric_data.quantile(0.10)
        filtered_data = metric_data[metric_data >= threshold]

        if len(filtered_data) < 10:
            filtered_data = metric_data

        base_values[metric] = filtered_data.mean()
        std_values[metric] = filtered_data.std() * 0.1

        # ì£¼ê°„ íŒ¨í„´
        learning_data['dayofweek'] = pd.to_datetime(learning_data['ì¼ êµ¬ë¶„']).dt.dayofweek
        weekly_avg = learning_data.groupby('dayofweek')[metric].mean()
        overall_avg = learning_data[metric].mean()
        if overall_avg > 0:
            weekly_patterns[metric] = (weekly_avg / overall_avg).to_dict()
        else:
            weekly_patterns[metric] = {i: 1.0 for i in range(7)}

    # ì˜ˆì¸¡ ë°ì´í„° ìƒì„±
    predictions = []
    last_date = daily['ì¼ êµ¬ë¶„'].max()
    np.random.seed(42)

    for i in range(1, days + 1):
        pred_date = last_date + timedelta(days=i)
        dayofweek = pred_date.dayofweek

        pred_row = {
            'ì¼ êµ¬ë¶„': pred_date.strftime('%Y-%m-%d'),
            'ë¹„ìš©_ì˜ˆì¸¡': max(0, float(base_values['ë¹„ìš©'] * weekly_patterns['ë¹„ìš©'].get(dayofweek, 1.0) + np.random.normal(0, std_values['ë¹„ìš©']))),
            'ë…¸ì¶œ_ì˜ˆì¸¡': max(0, int(base_values['ë…¸ì¶œ'] * weekly_patterns['ë…¸ì¶œ'].get(dayofweek, 1.0) + np.random.normal(0, std_values['ë…¸ì¶œ']))),
            'í´ë¦­_ì˜ˆì¸¡': max(0, int(base_values['í´ë¦­'] * weekly_patterns['í´ë¦­'].get(dayofweek, 1.0) + np.random.normal(0, std_values['í´ë¦­']))),
            'ì „í™˜ìˆ˜_ì˜ˆì¸¡': max(0, float(base_values['ì „í™˜ìˆ˜'] * weekly_patterns['ì „í™˜ìˆ˜'].get(dayofweek, 1.0) + np.random.normal(0, std_values['ì „í™˜ìˆ˜']))),
            'ì „í™˜ê°’_ì˜ˆì¸¡': max(0, float(base_values['ì „í™˜ê°’'] * weekly_patterns['ì „í™˜ê°’'].get(dayofweek, 1.0) + np.random.normal(0, std_values['ì „í™˜ê°’']))),
            'type': 'forecast'
        }
        predictions.append(pred_row)

    # ì‹¤ì œ ë°ì´í„° ì¶”ê°€
    actual = daily.tail(30).copy()
    actual['type'] = 'actual'
    actual = actual.rename(columns={
        'ë¹„ìš©': 'ë¹„ìš©_ì˜ˆì¸¡',
        'ë…¸ì¶œ': 'ë…¸ì¶œ_ì˜ˆì¸¡',
        'í´ë¦­': 'í´ë¦­_ì˜ˆì¸¡',
        'ì „í™˜ìˆ˜': 'ì „í™˜ìˆ˜_ì˜ˆì¸¡',
        'ì „í™˜ê°’': 'ì „í™˜ê°’_ì˜ˆì¸¡'
    })
    actual['ì¼ êµ¬ë¶„'] = actual['ì¼ êµ¬ë¶„'].dt.strftime('%Y-%m-%d')

    # í•©ì¹˜ê¸°
    forecast_df = pd.concat([actual, pd.DataFrame(predictions)], ignore_index=True)

    # ì €ì¥
    for timeframe in ['daily', 'detailed', 'weekly', 'monthly']:
        if timeframe == 'weekly':
            # ì£¼ë³„ ì§‘ê³„
            df_temp = forecast_df.copy()
            df_temp['ì¼ êµ¬ë¶„'] = pd.to_datetime(df_temp['ì¼ êµ¬ë¶„'])
            df_temp['ì£¼ êµ¬ë¶„'] = df_temp['ì¼ êµ¬ë¶„'].dt.to_period('W').astype(str)
            weekly = df_temp.groupby(['ì£¼ êµ¬ë¶„', 'type']).agg({
                'ë¹„ìš©_ì˜ˆì¸¡': 'sum',
                'ë…¸ì¶œ_ì˜ˆì¸¡': 'sum',
                'í´ë¦­_ì˜ˆì¸¡': 'sum',
                'ì „í™˜ìˆ˜_ì˜ˆì¸¡': 'sum',
                'ì „í™˜ê°’_ì˜ˆì¸¡': 'sum'
            }).reset_index()
            forecast_file = FORECAST_DIR / f'predictions_{timeframe}.csv'
            weekly.to_csv(forecast_file, index=False, encoding='utf-8')
        elif timeframe == 'monthly':
            # ì›”ë³„ ì§‘ê³„
            df_temp = forecast_df.copy()
            df_temp['ì¼ êµ¬ë¶„'] = pd.to_datetime(df_temp['ì¼ êµ¬ë¶„'])
            df_temp['ì›” êµ¬ë¶„'] = df_temp['ì¼ êµ¬ë¶„'].dt.to_period('M').astype(str)
            monthly = df_temp.groupby(['ì›” êµ¬ë¶„', 'type']).agg({
                'ë¹„ìš©_ì˜ˆì¸¡': 'sum',
                'ë…¸ì¶œ_ì˜ˆì¸¡': 'sum',
                'í´ë¦­_ì˜ˆì¸¡': 'sum',
                'ì „í™˜ìˆ˜_ì˜ˆì¸¡': 'sum',
                'ì „í™˜ê°’_ì˜ˆì¸¡': 'sum'
            }).reset_index()
            forecast_file = FORECAST_DIR / f'predictions_{timeframe}.csv'
            monthly.to_csv(forecast_file, index=False, encoding='utf-8')
        else:
            forecast_file = FORECAST_DIR / f'predictions_{timeframe}.csv'
            forecast_df.to_csv(forecast_file, index=False, encoding='utf-8')

    print(f"   âœ… ì˜ˆì¸¡ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
    print(f"   â”œ ì‹¤ì œ ë°ì´í„°: {len(actual)}ì¼")
    print(f"   â”” ì˜ˆì¸¡ ë°ì´í„°: {len(predictions)}ì¼")

    return forecast_df


def generate_metadata(df: pd.DataFrame, month_info: List[Dict]) -> Dict[str, Any]:
    """ë©”íƒ€ë°ì´í„° ìƒì„±"""
    print("\nğŸ“‹ ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")

    total_metrics = {
        'cost': float(df['ë¹„ìš©'].sum()),
        'impressions': int(df['ë…¸ì¶œ'].sum()),
        'clicks': int(df['í´ë¦­'].sum()),
        'conversions': int(df['ì „í™˜ìˆ˜'].sum()),
        'revenue': float(df['ì „í™˜ê°’'].sum())
    }

    kpis = {
        'ctr': round(total_metrics['clicks'] / total_metrics['impressions'] * 100, 2) if total_metrics['impressions'] > 0 else 0,
        'cpc': round(total_metrics['cost'] / total_metrics['clicks'], 0) if total_metrics['clicks'] > 0 else 0,
        'cpa': round(total_metrics['cost'] / total_metrics['conversions'], 0) if total_metrics['conversions'] > 0 else 0,
        'cvr': round(total_metrics['conversions'] / total_metrics['clicks'] * 100, 2) if total_metrics['clicks'] > 0 else 0,
        'roas': round(total_metrics['revenue'] / total_metrics['cost'] * 100, 0) if total_metrics['cost'] > 0 else 0
    }

    metadata = {
        'last_updated': datetime.now().isoformat(),
        'total_rows': len(df),
        'date_range': {
            'start': df['ì¼ êµ¬ë¶„'].min().strftime('%Y-%m-%d'),
            'end': df['ì¼ êµ¬ë¶„'].max().strftime('%Y-%m-%d')
        },
        'months': sorted(month_info, key=lambda x: x['month'], reverse=True),
        'total_metrics': total_metrics,
        'kpis': kpis,
        'processing_mode': 'lite'
    }

    meta_file = META_DIR / 'latest.json'
    with open(meta_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    print(f"   âœ… {meta_file.name} ì €ì¥ ì™„ë£Œ")
    print(f"\nğŸ“Š ì „ì²´ ì„±ê³¼ ìš”ì•½:")
    print(f"   â”œ ì´ ê´‘ê³ ë¹„: â‚©{total_metrics['cost']:,.0f}")
    print(f"   â”œ ì´ ì „í™˜ìˆ˜: {total_metrics['conversions']:,}ê±´")
    print(f"   â”” ROAS: {kpis['roas']}%")

    return metadata


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("ğŸš€ ë§ˆì¼€íŒ… ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ (ê²½ëŸ‰ ë²„ì „)")
    print("="*80)
    print("\nğŸ’¡ ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ: Prophet ë¯¸ì‚¬ìš©, ë‹¨ìˆœ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰")

    input_file = os.environ.get('INPUT_CSV_PATH', 'raw_data.csv')

    if not os.path.exists(input_file):
        print(f"\nâŒ ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_file}")
        sys.exit(1)

    try:
        # 1. ë°ì´í„° ë¡œë“œ
        df = load_and_clean_data(input_file)

        # 2. ë°ì´í„° ì •ì œ
        df = clean_and_convert_types(df)

        # 3. ì§€í‘œ ê³„ì‚°
        df = calculate_metrics(df)

        # 4. ì›”ë³„ ë¶„ë¦¬
        monthly_data = split_by_month(df)

        # 5. ì›”ë³„ CSV ì €ì¥
        month_info = save_monthly_csv(monthly_data)

        # 6. í†µê³„ ë¶„ì„
        statistics = calculate_statistics(df)

        # 7. ë‹¨ìˆœ ì˜ˆì¸¡ (Prophet ë¯¸ì‚¬ìš©)
        simple_forecast(df)

        # 8. ë©”íƒ€ë°ì´í„° ìƒì„±
        generate_metadata(df, month_info)

        print("\n" + "="*80)
        print("âœ… ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ! (ê²½ëŸ‰ ëª¨ë“œ)")
        print("="*80)
        print("\nìƒì„±ëœ íŒŒì¼:")
        print("   ğŸ“ data/forecast/")
        print("      â”œ predictions_daily.csv")
        print("      â”œ predictions_detailed.csv")
        print("      â”œ predictions_weekly.csv")
        print("      â”” predictions_monthly.csv")
        print("   ğŸ“ data/statistics/")
        print("      â”” statistics.json")
        print("   ğŸ“ data/meta/")
        print("      â”” latest.json")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
